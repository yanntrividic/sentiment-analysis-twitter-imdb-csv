<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>src.model.nlp_utils API documentation</title>
<meta name="description" content="Created on Mar 10, 2021 …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.model.nlp_utils</code></h1>
</header>
<section id="section-intro">
<p>Created on Mar 10, 2021</p>
<p>Toolkit to use basic NLP methods specific to our usecase.
@author: yann</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;
Created on Mar 10, 2021

Toolkit to use basic NLP methods specific to our usecase.
@author: yann
&#39;&#39;&#39;

from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize

# conversion table between various language
# TODO: remove comments once the following languages are implemented
EN = {&#39;name&#39;: &#39;english&#39;, &#39;en_name&#39;: &#39;english&#39;, &#39;639-1&#39;: &#39;en&#39;}
FR = {&#39;name&#39;: &#39;français&#39;, &#39;en_name&#39;: &#39;french&#39;, &#39;639-1&#39;: &#39;fr&#39;}
# DE = {&#39;name&#39;: &#39;deutsch&#39;, &#39;en_name&#39;: &#39;german&#39;, &#39;639-1&#39;: &#39;de&#39;}
# ES = {&#39;name&#39;: &#39;español&#39;, &#39;en_name&#39;: &#39;spanish&#39;, &#39;639-1&#39;: &#39;es&#39;}

SUPPORTED_LANG = [EN, FR]  # , DE, ES]


def convert_lang_format(to_convert, target=&#39;639-1&#39;):
    &#39;&#39;&#39;Converts the argument to its equivalent in the specified target format code and returns this value.
    Raises an error if the language is not found in SUPPORTED_LANG

    to_convert -- str to convert
    target -- target format (default value : &#39;639-1&#39;)
    &#39;&#39;&#39;
    for lang in SUPPORTED_LANG:  # we iterate through the supported languages
        for key in lang:
            if to_convert.lower() == lang[key]:
                return lang[target]
    raise ValueError(&#34;The language you try to use is not supported by this program.&#34;)


def tokenize_and_remove_stopwords(sent, lang):
    &#39;&#39;&#39;Tokenizing means to separate semantic groups of words. Stopwords are words that holds no semantic meaning,
    for example &#39;the&#39;, &#39;of&#39;, etc., are stopwords for the english language.

    sent -- A sentence in natural language
    lang -- The language of the sentence
    &#39;&#39;&#39;

    if not(isinstance(sent, str)):
            raise ValueError(&#34;This parameter has to be a sentence.&#34;)

    lang = convert_lang_format(lang, &#34;en_name&#34;)

    stop_words = set(stopwords.words(lang))
    word_tokens = word_tokenize(sent)

    return [w for w in word_tokens if w not in stop_words]


def stem_words(words):
    &#39;&#39;&#39;Stemming consists in reducing words to their word stem (i.e. base or root form)
    The Porter stemmer is english specific. For french, an option could be the &#39;spacy&#39; module and its lemma_ attribute.
    https://stackoverflow.com/questions/13131139/lemmatize-french-text

    words -- a list of english words
    return a list of stemmed words
    &#39;&#39;&#39;
    ps = PorterStemmer()
    stemmed = []
    for w in words:
        stemmed.append(ps.stem(w))
    return stemmed


def lemmatize_words(words):
    &#39;&#39;&#39;Lemmatizing is similar to stemming as it changes words without changing the essence of the words.
    Like stem_words, models for other languages than english are more difficult to find, this function
    only works with english words for now (WordNet is an english database).

    words -- a list of english words
    return a list of lemmatized words
    &#39;&#39;&#39;

    lemmatizer = WordNetLemmatizer()
    lemmatized = []
    for w in words:
        lemmatized.append(lemmatizer.lemmatize(w))
        # will do a better job if we give it the POS tagging as a second parameter
    return lemmatized


def words_in_sentence(sentence, words):
    print(sentence)
    lsent = sentence.lower()
    for word in words:
        word = word.lower()

    for word in words:
        if word in lsent:
            return True

    return False</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="src.model.nlp_utils.convert_lang_format"><code class="name flex">
<span>def <span class="ident">convert_lang_format</span></span>(<span>to_convert, target='639-1')</span>
</code></dt>
<dd>
<div class="desc"><p>Converts the argument to its equivalent in the specified target format code and returns this value.
Raises an error if the language is not found in SUPPORTED_LANG</p>
<p>to_convert &ndash; str to convert
target &ndash; target format (default value : '639-1')</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_lang_format(to_convert, target=&#39;639-1&#39;):
    &#39;&#39;&#39;Converts the argument to its equivalent in the specified target format code and returns this value.
    Raises an error if the language is not found in SUPPORTED_LANG

    to_convert -- str to convert
    target -- target format (default value : &#39;639-1&#39;)
    &#39;&#39;&#39;
    for lang in SUPPORTED_LANG:  # we iterate through the supported languages
        for key in lang:
            if to_convert.lower() == lang[key]:
                return lang[target]
    raise ValueError(&#34;The language you try to use is not supported by this program.&#34;)</code></pre>
</details>
</dd>
<dt id="src.model.nlp_utils.lemmatize_words"><code class="name flex">
<span>def <span class="ident">lemmatize_words</span></span>(<span>words)</span>
</code></dt>
<dd>
<div class="desc"><p>Lemmatizing is similar to stemming as it changes words without changing the essence of the words.
Like stem_words, models for other languages than english are more difficult to find, this function
only works with english words for now (WordNet is an english database).</p>
<p>words &ndash; a list of english words
return a list of lemmatized words</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def lemmatize_words(words):
    &#39;&#39;&#39;Lemmatizing is similar to stemming as it changes words without changing the essence of the words.
    Like stem_words, models for other languages than english are more difficult to find, this function
    only works with english words for now (WordNet is an english database).

    words -- a list of english words
    return a list of lemmatized words
    &#39;&#39;&#39;

    lemmatizer = WordNetLemmatizer()
    lemmatized = []
    for w in words:
        lemmatized.append(lemmatizer.lemmatize(w))
        # will do a better job if we give it the POS tagging as a second parameter
    return lemmatized</code></pre>
</details>
</dd>
<dt id="src.model.nlp_utils.stem_words"><code class="name flex">
<span>def <span class="ident">stem_words</span></span>(<span>words)</span>
</code></dt>
<dd>
<div class="desc"><p>Stemming consists in reducing words to their word stem (i.e. base or root form)
The Porter stemmer is english specific. For french, an option could be the 'spacy' module and its lemma_ attribute.
<a href="https://stackoverflow.com/questions/13131139/lemmatize-french-text">https://stackoverflow.com/questions/13131139/lemmatize-french-text</a></p>
<p>words &ndash; a list of english words
return a list of stemmed words</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stem_words(words):
    &#39;&#39;&#39;Stemming consists in reducing words to their word stem (i.e. base or root form)
    The Porter stemmer is english specific. For french, an option could be the &#39;spacy&#39; module and its lemma_ attribute.
    https://stackoverflow.com/questions/13131139/lemmatize-french-text

    words -- a list of english words
    return a list of stemmed words
    &#39;&#39;&#39;
    ps = PorterStemmer()
    stemmed = []
    for w in words:
        stemmed.append(ps.stem(w))
    return stemmed</code></pre>
</details>
</dd>
<dt id="src.model.nlp_utils.tokenize_and_remove_stopwords"><code class="name flex">
<span>def <span class="ident">tokenize_and_remove_stopwords</span></span>(<span>sent, lang)</span>
</code></dt>
<dd>
<div class="desc"><p>Tokenizing means to separate semantic groups of words. Stopwords are words that holds no semantic meaning,
for example 'the', 'of', etc., are stopwords for the english language.</p>
<p>sent &ndash; A sentence in natural language
lang &ndash; The language of the sentence</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tokenize_and_remove_stopwords(sent, lang):
    &#39;&#39;&#39;Tokenizing means to separate semantic groups of words. Stopwords are words that holds no semantic meaning,
    for example &#39;the&#39;, &#39;of&#39;, etc., are stopwords for the english language.

    sent -- A sentence in natural language
    lang -- The language of the sentence
    &#39;&#39;&#39;

    if not(isinstance(sent, str)):
            raise ValueError(&#34;This parameter has to be a sentence.&#34;)

    lang = convert_lang_format(lang, &#34;en_name&#34;)

    stop_words = set(stopwords.words(lang))
    word_tokens = word_tokenize(sent)

    return [w for w in word_tokens if w not in stop_words]</code></pre>
</details>
</dd>
<dt id="src.model.nlp_utils.words_in_sentence"><code class="name flex">
<span>def <span class="ident">words_in_sentence</span></span>(<span>sentence, words)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def words_in_sentence(sentence, words):
    print(sentence)
    lsent = sentence.lower()
    for word in words:
        word = word.lower()

    for word in words:
        if word in lsent:
            return True

    return False</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src.model" href="index.html">src.model</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="src.model.nlp_utils.convert_lang_format" href="#src.model.nlp_utils.convert_lang_format">convert_lang_format</a></code></li>
<li><code><a title="src.model.nlp_utils.lemmatize_words" href="#src.model.nlp_utils.lemmatize_words">lemmatize_words</a></code></li>
<li><code><a title="src.model.nlp_utils.stem_words" href="#src.model.nlp_utils.stem_words">stem_words</a></code></li>
<li><code><a title="src.model.nlp_utils.tokenize_and_remove_stopwords" href="#src.model.nlp_utils.tokenize_and_remove_stopwords">tokenize_and_remove_stopwords</a></code></li>
<li><code><a title="src.model.nlp_utils.words_in_sentence" href="#src.model.nlp_utils.words_in_sentence">words_in_sentence</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>